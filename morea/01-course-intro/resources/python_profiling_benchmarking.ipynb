{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9ddf3c",
   "metadata": {},
   "source": [
    "## Code Profiling vs. Benchmarking\n",
    "\n",
    "### 1. Profiling\n",
    "\n",
    "* The objective of profiling is to analyze where time and resources are spent within a program.\n",
    "\n",
    "* Examines the runtime behavior of your program, e.g.,\n",
    "  - How long each function takes to execute\n",
    "  - How many times a function is called\n",
    "  - Memory usage of certain variables or data structures\n",
    "\n",
    "* Output: Detailed report showing the time spent in each function, the number of calls, and possibly the call hierarchy (which functions call which).\n",
    "\n",
    "* Main focus of courses like ICS432\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99b863a",
   "metadata": {},
   "source": [
    "## 2. Benchmarking\n",
    "\n",
    "* The objective of benchmarking is to measure the overall performance of a program or system.\n",
    "\n",
    "* Involves running a program under specific conditions and measuring metrics such as:\n",
    "  - Execution time (runtime): The total time it takes for a program or a specific operation to complete from start to finish.\n",
    "  - Throughput: The amount of work a system can perform or data it can process in a given amount of time.\n",
    "  - Latency: The time it takes to initiate or complete a specific operation or request.\n",
    "\n",
    "* Focuses on the end-to-end performance of an entire program or system.\n",
    "\n",
    "* Output: Measurements for a set of performance metrics, such as the total time taken to complete a task, the number of operations performed per second, or the memory usage during execution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d69be5",
   "metadata": {},
   "source": [
    "## Relevance to BDA\n",
    "\n",
    "* Process terabytes/petabytes efficiently\n",
    "  * Avoid prohibitive slowdowns\n",
    "* Efficiently manage the cost of workign with large datasets\n",
    "  * Optimize configurations or plateform choices for cost-effectiveness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9340886c",
   "metadata": {},
   "source": [
    "## Importance of Profiling:\n",
    "\n",
    "* **Resource Efficiency & Algorithm Optimization**: \n",
    "  * Helps identify inefficient code sections that consume excessive CPU, memory, or I/O resources\n",
    "  * Reveals which parts of algorithms are the most time-consuming\n",
    "    * Needed for targeted optimizations\n",
    "    * Main focus of ICS432\n",
    "\n",
    "* **Bottleneck Identification**:  \n",
    "  * When working with systems like Hadoop or Spark, profiling can pinpoint where bottlenecks occur\n",
    "  * Essential for optimizing workflows and improving overall system performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c367c8",
   "metadata": {},
   "source": [
    "## Importance of Benchmarking\n",
    "\n",
    "* **Performance Measurement**\n",
    "   * Evaluates entire data processing pipeline\n",
    "   * Helps understand system behavior under various loads\n",
    "\n",
    "* **System Comparison**\n",
    "   * Enables comparison of frameworks, storage solutions, and hardware\n",
    "   * Facilitates informed decisions based on quantitative data\n",
    "\n",
    "* **Capacity Planning**\n",
    "   * Helps determine system limits\n",
    "   * Allows planning for future scaling needs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96805e17",
   "metadata": {},
   "source": [
    "## Code Execution Time Profiling wtih `time`\n",
    "\n",
    "* Using `time` module\n",
    "* Simple to use for quick measurements\n",
    "* Less accurate due to system clock resolution\n",
    "* Includes Python interpreter startup time\n",
    "* Suitable for longer-running processes\n",
    "\n",
    "* Why It Matters\n",
    "- High User Time: Optimize your code\n",
    "- High System Time: Optimize system calls or I/O operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12f05537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_running_func(num_iterations=10, sleep_time=0.1):\n",
    "    \"\"\"\n",
    "    A function that simulates a long-running process.\n",
    "\n",
    "    Args:\n",
    "    num_iterations (int): Number of iterations to run. Default is 10.\n",
    "    sleep_time (float): Time to sleep in each iteration in seconds. Default is 0.1.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    for _ in range(num_iterations): \n",
    "        counter += 1\n",
    "        time.sleep(sleep_time)  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42416aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 1.0322108268737793 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "long_running_func()\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6740f340",
   "metadata": {},
   "source": [
    "## Profiling with `IPython` Magic Command: `%time`\n",
    "\n",
    "- Measures the execution time of a single run of a function or statement\n",
    "\n",
    "```python\n",
    "%time long_running_func()\n",
    "```\n",
    "\n",
    "* What It Does\n",
    "  * Executes `long_running_func()` and measures user, sys, \n",
    "\n",
    "* Measures:\n",
    "  * User Time: time spent running your program's code.\n",
    "\n",
    "  * System Time: time spent by the operating system working for your program\n",
    "- Examples:\n",
    "  - Reading or writing files\n",
    "  - Allocating memory\n",
    "  - Handling network operations\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d43b7dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.41 ms, sys: 1.82 ms, total: 3.24 ms\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%time long_running_func(sleep_time=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d29364e",
   "metadata": {},
   "source": [
    "## Using `timeit` module\n",
    "\n",
    "* Designed for accurate timing of small code snippets\n",
    "* Runs code multiple times for statistical accuracy\n",
    "* Attempts to factor out Python interpreter overhead\n",
    "* Preferred for benchmarking and comparing code snippets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ff805af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single run time: 1.0530465840001852 seconds\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "# Single run\n",
    "single_run_time = timeit.timeit(long_running_func, number=1)\n",
    "print(f\"Single run time: {single_run_time} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f8cce3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time over 1000 runs: 1.03575693340008 seconds\n"
     ]
    }
   ],
   "source": [
    "average_time = timeit.timeit(long_running_func, number=10) / 10\n",
    "print(f\"Average time over 10 runs: {average_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afc0d37",
   "metadata": {},
   "source": [
    "\n",
    "### Using `cProfile` for detailed profiling\n",
    "- A built-in profiling library in Python to produce detailed statistics about function calls in a Python program\n",
    "- Useful for identifying bottlenecks in larger programs\n",
    "- Can sort results by various metrics (e.g., cumulative time, call count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e52d9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         3 function calls in 0.000 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "\n",
    "cProfile.run('long_running_func')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0787914",
   "metadata": {},
   "source": [
    "### Output Explanation\n",
    "\n",
    "```\n",
    "         3 function calls in 0.000 seconds\n",
    "\n",
    "   Ordered by: standard name\n",
    "\n",
    "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
    "        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\n",
    "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
    "```\n",
    "\n",
    "- Indicates 3 function calls were made\n",
    "- Total time appears to be less than 0.001 seconds (rounded to 0.000)\n",
    "  * cProfile measures CPU time, not wall time\n",
    "\n",
    "1. ncalls: Number of calls to the function\n",
    "2. tottime: Total time spent in the function (excluding time in subfunctions)\n",
    "3. percall: Average time spent per call (tottime / ncalls)\n",
    "4. cumtime: Cumulative time spent in the function and all subfunctions\n",
    "5. percall: Average cumulative time per call\n",
    "6. filename:lineno(function): Location and name of the function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dc7bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using `psutil` for overall process memory\n",
    "* Provides overall memory usage of the Python process\n",
    "* Faster than memory_profiler for whole-program memory tracking\n",
    "*  Can track other system resources as well (CPU, disk I/O, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24fec8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 126.265625 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import os\n",
    "\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024  # in MB\n",
    "\n",
    "print(f\"Current memory usage: {get_memory_usage()} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c8cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Size Profiling\n",
    "\n",
    "### Using `sys.getsizeof()`\n",
    "* Provides basic size information for Python objects\n",
    "* Does not account for referenced objects (e.g., list contents)\n",
    "* Quick and simple for basic data structures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b900718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data: 120 bytes\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "data = [1, 2, 3, 4, 5]\n",
    "print(f\"Size of data: {sys.getsizeof(data)} bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce8b358a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data: 152 bytes\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ]\n",
    "print(f\"Size of data: {sys.getsizeof(data)} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b573b0cd",
   "metadata": {},
   "source": [
    "### Using `pympler` for complex objects\n",
    "* More accurate size estimation for complex, nested objects\n",
    "* Accounts for the full object graph\n",
    "* Slower than sys.getsizeof() but more comprehensive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c319c1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pympler\n",
      "  Obtaining dependency information for pympler from https://files.pythonhosted.org/packages/79/4f/a6a2e2b202d7fd97eadfe90979845b8706676b41cbd3b42ba75adf329d1f/Pympler-1.1-py3-none-any.whl.metadata\n",
      "  Downloading Pympler-1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading Pympler-1.1-py3-none-any.whl (165 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.8/165.8 kB\u001b[0m \u001b[31m900.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pympler\n",
      "Successfully installed pympler-1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pympler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15951319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of complex_data: 280 bytes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pympler import asizeof\n",
    "\n",
    "complex_data = {'a': [1, 2, 3], 'b': {'c': 4, 'd': 5}}\n",
    "print(f\"Total size of complex_data: {asizeof.asizeof(complex_data)} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c0e4a9",
   "metadata": {},
   "source": [
    "## RAM Usage Profiling Using `memory_profiler`\n",
    "* Tracks line-by-line memory usage\n",
    "* Useful for identifying memory-intensive operations\n",
    "* Can be slower due to frequent memory measurements\n",
    "* Install with: pip install memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71cc093a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: memory_profiler in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (0.61.0)\n",
      "Requirement already satisfied: psutil in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from memory_profiler) (5.9.4)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b40fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6cbc64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "463ca46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def memory_hungry_function():\n",
    "    big_list = [i for i in range(1000000)]\n",
    "    del big_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c890938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find file /var/folders/5l/gk6s2xx10qs0mkg4_9_vyp3h0000gn/T/ipykernel_30373/1498337545.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%mprun -f memory_hungry_function memory_hungry_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d4a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
