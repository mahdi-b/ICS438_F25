{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c0e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade openai\n",
    "#pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f3f7bc",
   "metadata": {},
   "source": [
    "### Understanding LangChain: A Modular Framework for LLMs\n",
    "\n",
    "* LangChain is fundamentally a framework designed for Large Language Models (LLMs).\n",
    "\n",
    "* It enables the development of various applications such as chatbots, Generative Question-Answering (GQA), content summarization, and beyond.\n",
    "\n",
    "* The essence of the framework lies in its ability to \"chain\" diverse components, facilitating the creation of sophisticated functionalities utilizing LLMs.\n",
    "  * Chains are composed of various elements across different modules, including:\n",
    "\n",
    "* These are pre-designed templates tailored for specific interactions, ranging from chatbot dialogues to Explain Like I'm Five (ELI5) question-responding formats.\n",
    "\n",
    "* This encompasses a range of Large Language Models such as ChatGPT, Bard, Claude, etc.\n",
    "* Agents leverage LLMs to determine necessary actions. They can employ tools like web search or calculators, integrated into a cohesive operational loop.\n",
    "* Incorporating both short-term and long-term memory functionalities.\n",
    "\n",
    "* Our primary aim here is to delve into the functionality that enables the transformation of unstructured text into structured data, extracting valuable insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb8e12",
   "metadata": {},
   "source": [
    "### Core Components of LangChain\n",
    "\n",
    "* Chains are composed of various modules that can be combined to enhance the capabilities of LLMs.\n",
    "\n",
    "Key Modules Include:\n",
    "\n",
    "  * Prompt Templates: Customizable templates suited for different interaction styles, including chatbot  conversations.\n",
    "  * LLMs: Incorporation of various Large Language Models such as ChatGPT, Bard, Claude, etc.\n",
    "  *  Agents: Agents utilize LLMs to determine the necessary actions, employing tools like web searches or calculators within a logical operational loop.\n",
    "  * Memory Modules: These include both short-term and long-term memory functionalities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dac5307c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AR3IVHLklkzZ6l35psylQJdb9KWTV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Honolulu', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1731010895, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_159d8341cc', usage=CompletionUsage(completion_tokens=2, prompt_tokens=34, total_tokens=36, completion_tokens_details=CompletionTokensDetails(audio_tokens=0, reasoning_tokens=0, accepted_prediction_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "prompt = \"\"\" What is the most populated city in the state of Hawaii. \n",
    "Provide city name and no additional information.\"\"\"\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": prompt\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"Honolulu\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=2048,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  response_format={\n",
    "    \"type\": \"text\"\n",
    "  }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b8dbc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Honolulu'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d74e5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d1cdfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"What is the most populated city in the state of Hawaii. \n",
    "Provide city name and no additional information.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57db3165",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2614340b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Honolulu', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 28, 'total_tokens': 30, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4a0a8fd9-2bdc-4555-8d10-76f1eaf08a2d-0', usage_metadata={'input_tokens': 28, 'output_tokens': 2, 'total_tokens': 30})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8813f9dd",
   "metadata": {},
   "source": [
    "### Prompts Are First Class objects in LangChain\n",
    "\n",
    "* Prompts can be easily tailored to incorporate runtime variables.\n",
    "* They can also be customized with examples for more precise and context-relevant responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9791241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"What is the most populated city in the state of {state}.\n",
    "\n",
    "Provide city name and no additional information.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c52da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f5c20ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Honolulu'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"state\": \"Hawaii\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99901955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Los Angeles'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"state\": \"California\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6045f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Atlanta'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"state\": \"Georgia\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b8a5d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"What is the most populated city in the state provided below.\n",
    "\n",
    "Provide city name and no additional information. \n",
    "\n",
    "Examples:\n",
    "\n",
    "State: Hawaii\n",
    "City: Honolulu\n",
    "\n",
    "State: California\n",
    "City: Los Angeles\n",
    "\n",
    "State: {state}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_str)\n",
    "\n",
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33f4e2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='City: Atlanta', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 51, 'total_tokens': 54, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9f4f4107-fcfa-480b-a704-2adc248e9ede-0', usage_metadata={'input_tokens': 51, 'output_tokens': 3, 'total_tokens': 54})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"state\": \"Georgia\"})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efcb73f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'City: Atlanta'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38054a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"What is the most populated city in the state provided below.\n",
    "\n",
    "Provide city name and no additional information. \n",
    "\n",
    "Examples:\n",
    "\n",
    "State: Hawaii\n",
    "{{\"City\": \"Honolulu\"}}\n",
    "\n",
    "State: California\n",
    "{{\"City\": \"Los Angeles\"}}\n",
    "\n",
    "State: {state}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_str)\n",
    "\n",
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c6034cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='{\"City\": \"Atlanta\"}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 56, 'total_tokens': 62, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c19ed859-2ebd-4190-8af6-ef56ac3a107d-0', usage_metadata={'input_tokens': 56, 'output_tokens': 6, 'total_tokens': 62})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"state\": \"Georgia\"})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5cfc21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"City\": \"Atlanta\"}'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c313d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'City': 'Atlanta'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "data = json.loads(response.content)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71089bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Atlanta'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"City\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef6f587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix = \"\"\"What is the most populated city in the state provided below. \n",
    "Provide city name and no additional information. \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f910569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ExampleState': 'Hawaii', 'ExampleCity': 'Honolulu'},\n",
       " {'ExampleState': 'California', 'ExampleCity': 'Los Angeles'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_examples = [\n",
    "    {\"ExampleState\": \"Hawaii\", \"ExampleCity\": \"Honolulu\"},\n",
    "    {\"ExampleState\": \"California\", \"ExampleCity\": \"Los Angeles\"}   \n",
    "]\n",
    "prompt_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27eabaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: {ExampleState}\n",
      "City: {ExampleCity}\n"
     ]
    }
   ],
   "source": [
    "example_prompt_str =\"State: {ExampleState}\\nCity: {ExampleCity}\"\n",
    "print(example_prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "652ecbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['ExampleCity', 'ExampleState'], input_types={}, partial_variables={}, template='State: {ExampleState}\\nCity: {ExampleCity}')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt = PromptTemplate(input_variables=[\"ExampleState\", \"ExampleCity\"], template = example_prompt_str)\n",
    "\n",
    "example_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90ae69fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: Hawaii\n",
      "City: Honolulu\n"
     ]
    }
   ],
   "source": [
    "print(example_prompt.format(**prompt_examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f35ecc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: California\n",
      "City: Los Angeles\n"
     ]
    }
   ],
   "source": [
    "print(example_prompt.format(**prompt_examples[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eab28255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "execute_fewshot_prompt = FewShotPromptTemplate(\n",
    "    prefix = prompt_prefix,\n",
    "    input_variables=[\"state\"],\n",
    "    examples= prompt_examples,\n",
    "    example_prompt = example_prompt,\n",
    "    example_separator=\"\\n\\n\",\n",
    "    suffix = \"State: {state}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "827de395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the most populated city in the state provided below. \n",
      "Provide city name and no additional information. \n",
      "\n",
      "State: Hawaii\n",
      "City: Honolulu\n",
      "\n",
      "State: California\n",
      "City: Los Angeles\n",
      "\n",
      "State: Georgia\n"
     ]
    }
   ],
   "source": [
    "data = {\"state\": \"Georgia\"}\n",
    "print(execute_fewshot_prompt.format(**data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93c04532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='City: Atlanta', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 49, 'total_tokens': 52, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d80f6e18-e2d2-4581-bc8b-5445415c859f-0', usage_metadata={'input_tokens': 49, 'output_tokens': 3, 'total_tokens': 52})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = execute_fewshot_prompt | model\n",
    "chain.invoke(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "465de8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4fec0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CityParser(BaseModel):\n",
    "    \"\"\"\n",
    "    this object holds information about the most populated city in the \n",
    "    given state.\n",
    "    \"\"\"\n",
    "    City: str = Field(..., description=\"The name of the most populous city\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b471bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "cityParser = PydanticOutputParser(pydantic_object=CityParser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c40c4f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CityParser(City='Atlanta')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = cityParser.parse(\"\"\"{\"City\": \"Atlanta\"}\"\"\")\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a672d439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"this object holds information about the most populated city in the \\ngiven state.\", \"properties\": {\"City\": {\"description\": \"The name of the most populous city\", \"title\": \"City\", \"type\": \"string\"}}, \"required\": [\"City\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "output_parser = PydanticOutputParser(pydantic_object=CityParser)\n",
    "print(output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0c14cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix = \"\"\" What is the most populated city for {state}. \n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f102b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_prefix,\n",
    "    input_variables=[\"state\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2d7457cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What is the most populated city for Georgia. \n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"this object holds information about the most populated city in the \\ngiven state.\", \"properties\": {\"City\": {\"description\": \"The name of the most populous city\", \"title\": \"City\", \"type\": \"string\"}}, \"required\": [\"City\"]}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(**data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6e6d7786",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model\n",
    "output = chain.invoke(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e3cf5ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"City\": \"Atlanta\"\\n}'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ecf7d528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CityParser(City='Atlanta')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cityParser.parse(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f0658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class PersonDetails(BaseModel):\n",
    "    \"\"\"\n",
    "    this object holds information about a person including their preferred activity, name and location (city).\n",
    "    \"\"\"\n",
    "    name: str = Field(..., description=\"The name of the person\") \n",
    "    hobby: str = Field(..., description=\"The preferred activity \") \n",
    "    location: str = Field(..., description=\"The city where the person lives\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "885335b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"this object holds information about a person including their preferred activity, name and location (city).\", \"properties\": {\"name\": {\"description\": \"The name of the person\", \"title\": \"Name\", \"type\": \"string\"}, \"hobby\": {\"description\": \"The preferred activity \", \"title\": \"Hobby\", \"type\": \"string\"}, \"location\": {\"description\": \"The city where the person lives\", \"title\": \"Location\", \"type\": \"string\"}}, \"required\": [\"name\", \"hobby\", \"location\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "person_idetail_parser = PydanticOutputParser(pydantic_object=PersonDetails)\n",
    "print(person_idetail_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc3d7e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix = \"\"\"\n",
    "The person said something below about themselves. Please parse only the fields of interests; those are\n",
    "name, preferred activity and location.\n",
    "{what_person_said}\n",
    "{format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ae9c728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The person said something below about themselves. Please parse only the fields of interests; those are\n",
      "name, preferred and location.\n",
      "Hello there\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"this object holds information about a person including their preferred activity, name and location (city).\", \"properties\": {\"name\": {\"description\": \"The name of the person\", \"title\": \"Name\", \"type\": \"string\"}, \"hobby\": {\"description\": \"The preferred activity \", \"title\": \"Hobby\", \"type\": \"string\"}, \"location\": {\"description\": \"The city where the person lives\", \"title\": \"Location\", \"type\": \"string\"}}, \"required\": [\"name\", \"hobby\", \"location\"]}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_prefix,\n",
    "    input_variables=[\"what_person_said\"],\n",
    "    partial_variables={\"format_instructions\": person_idetail_parser.get_format_instructions()}\n",
    ")\n",
    "print(prompt.format(what_person_said= \"Hello there\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9788e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model\n",
    "response = chain.invoke({\"what_person_said\": \"Hi, my name is Mahdi, I am in Honolulu, and I like surfing\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afa6c8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"Mahdi\",\n",
      "    \"hobby\": \"surfing\",\n",
      "    \"location\": \"Honolulu\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c0fe10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PersonDetails(name='Mahdi', hobby='surfing', location='Honolulu')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_idetail_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d707fe6",
   "metadata": {},
   "source": [
    "### Current Preferred Way \n",
    "- Leverage the tool usage capabilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1cdec95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CityParser(City='Atlanta')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm = model.with_structured_output(CityParser)\n",
    "structured_chain = prompt | structured_llm\n",
    "structured_chain.invoke({\"state\": \"Georgia\"})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
