{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c0e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade openai\n",
    "#pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f3f7bc",
   "metadata": {},
   "source": [
    "### Understanding LangChain: A Modular Framework for LLMs\n",
    "\n",
    "* LangChain is fundamentally a framework designed for Large Language Models (LLMs).\n",
    "\n",
    "* It enables the development of various applications such as chatbots, Generative Question-Answering (GQA), content summarization, and beyond.\n",
    "\n",
    "* The essence of the framework lies in its ability to \"chain\" diverse components, facilitating the creation of sophisticated functionalities utilizing LLMs.\n",
    "  * Chains are composed of various elements across different modules, including:\n",
    "\n",
    "* These are pre-designed templates tailored for specific interactions, ranging from chatbot dialogues to Explain Like I'm Five (ELI5) question-responding formats.\n",
    "\n",
    "* This encompasses a range of Large Language Models such as ChatGPT, Bard, Claude, etc.\n",
    "* Agents leverage LLMs to determine necessary actions. They can employ tools like web search or calculators, integrated into a cohesive operational loop.\n",
    "* Incorporating both short-term and long-term memory functionalities.\n",
    "\n",
    "* Our primary aim here is to delve into the functionality that enables the transformation of unstructured text into structured data, extracting valuable insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb8e12",
   "metadata": {},
   "source": [
    "### Core Components of LangChain\n",
    "\n",
    "* Chains are composed of various modules that can be combined to enhance the capabilities of LLMs.\n",
    "\n",
    "Key Modules Include:\n",
    "\n",
    "  * Prompt Templates: Customizable templates suited for different interaction styles, including chatbot  conversations.\n",
    "  * LLMs: Incorporation of various Large Language Models such as ChatGPT, Bard, Claude, etc.\n",
    "  *  Agents: Agents utilize LLMs to determine the necessary actions, employing tools like web searches or calculators within a logical operational loop.\n",
    "  * Memory Modules: These include both short-term and long-term memory functionalities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dac5307c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AOVj1u94YOzazBYUVVsKuWk15QdQP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Honolulu', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1730405187, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_159d8341cc', usage=CompletionUsage(completion_tokens=2, prompt_tokens=34, total_tokens=36, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "prompt = \"\"\" What is the most populated city in the state of Hawaii. \n",
    "Provide city name and no additional information.\"\"\"\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": prompt\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"Honolulu\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=2048,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  response_format={\n",
    "    \"type\": \"text\"\n",
    "  }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b8dbc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Honolulu'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d74e5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06094074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d1cdfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"What is the most populated city in the state of Hawaii. \n",
    "Provide city name and no additional information.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57db3165",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2614340b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Honolulu', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 28, 'total_tokens': 30, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-70a704b7-a9de-4866-9d9e-570e9ca46ecf-0', usage_metadata={'input_tokens': 28, 'output_tokens': 2, 'total_tokens': 30})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8813f9dd",
   "metadata": {},
   "source": [
    "### Prompts Are First Class objects in LangChain\n",
    "\n",
    "* Prompts can be easily tailored to incorporate runtime variables.\n",
    "* They can also be customized with examples for more precise and context-relevant responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9791241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"What is the most populated city in the state of {state}.\n",
    "\n",
    "Provide city name and no additional information.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c52da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f5c20ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Honolulu'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"state\": \"Hawaii\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99901955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Los Angeles'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"state\": \"California\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6045f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Atlanta'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"state\": \"Georgia\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b8a5d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"What is the most populated city in the state provided below.\n",
    "\n",
    "Provide city name and no additional information. \n",
    "\n",
    "Examples:\n",
    "\n",
    "State: Hawaii\n",
    "City: Honolulu\n",
    "\n",
    "State: California\n",
    "City: Los Angeles\n",
    "\n",
    "State: {state}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_str)\n",
    "\n",
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33f4e2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='City: Atlanta', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 51, 'total_tokens': 54, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a7b1eb9d-51a4-4b0d-a271-dd391f3e4170-0', usage_metadata={'input_tokens': 51, 'output_tokens': 3, 'total_tokens': 54})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"state\": \"Georgia\"})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efcb73f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'City: Atlanta'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38054a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"What is the most populated city in the state provided below.\n",
    "\n",
    "Provide city name and no additional information. \n",
    "\n",
    "Examples:\n",
    "\n",
    "State: Hawaii\n",
    "{{\"City\": \"Honolulu\"}}\n",
    "\n",
    "State: California\n",
    "{{\"City\": \"Los Angeles\"}}\n",
    "\n",
    "State: {state}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_str)\n",
    "\n",
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c6034cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='{\"City\": \"Atlanta\"}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 56, 'total_tokens': 62, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ff3d71f4-dce8-4295-8756-dc7044a7fa64-0', usage_metadata={'input_tokens': 56, 'output_tokens': 6, 'total_tokens': 62})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"state\": \"Georgia\"})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5cfc21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"City\": \"Atlanta\"}'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c313d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'City': 'Atlanta'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "data = json.loads(response.content)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71089bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Atlanta'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"City\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef6f587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix = \"\"\"What is the most populated city in the state provided below. \n",
    "Provide city name and no additional information. \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f910569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ExampleState': 'Hawaii', 'ExampleCity': 'Honolulu'},\n",
       " {'ExampleState': 'California', 'ExampleCity': 'Los Angeles'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_examples = [\n",
    "    {\"ExampleState\": \"Hawaii\", \"ExampleCity\": \"Honolulu\"},\n",
    "    {\"ExampleState\": \"California\", \"ExampleCity\": \"Los Angeles\"}   \n",
    "]\n",
    "prompt_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27eabaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: {ExampleState}\n",
      "City: {ExampleCity}\n"
     ]
    }
   ],
   "source": [
    "example_prompt_str =\"State: {ExampleState}\\nCity: {ExampleCity}\"\n",
    "print(example_prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "652ecbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['ExampleCity', 'ExampleState'], input_types={}, partial_variables={}, template='State: {ExampleState}\\nCity: {ExampleCity}')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt = PromptTemplate(input_variables=[\"ExampleState\", \"ExampleCity\"], template = example_prompt_str)\n",
    "\n",
    "example_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90ae69fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: Hawaii\n",
      "City: Honolulu\n"
     ]
    }
   ],
   "source": [
    "print(example_prompt.format(**prompt_examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f35ecc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: California\n",
      "City: Los Angeles\n"
     ]
    }
   ],
   "source": [
    "print(example_prompt.format(**prompt_examples[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eab28255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "execute_fewshot_prompt = FewShotPromptTemplate(\n",
    "    prefix = prompt_prefix,\n",
    "    input_variables=[\"state\"],\n",
    "    examples= prompt_examples,\n",
    "    example_prompt = example_prompt,\n",
    "    example_separator=\"\\n\\n\",\n",
    "    suffix = \"State: {state}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "827de395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the most populated city in the state provided below. \n",
      "Provide city name and no additional information. \n",
      "\n",
      "State: Hawaii\n",
      "City: Honolulu\n",
      "\n",
      "State: California\n",
      "City: Los Angeles\n",
      "\n",
      "State: Georgia\n"
     ]
    }
   ],
   "source": [
    "data = {\"state\": \"Georgia\"}\n",
    "print(execute_fewshot_prompt.format(**data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93c04532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='City: Atlanta', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 49, 'total_tokens': 52, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-cc4b1420-0625-431b-8c9b-163d895504a8-0', usage_metadata={'input_tokens': 49, 'output_tokens': 3, 'total_tokens': 52})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = execute_fewshot_prompt | model\n",
    "chain.invoke(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "465de8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4fec0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CityParser(BaseModel):\n",
    "    \"\"\"\n",
    "    this object holds information about the most populated city in the \n",
    "    given state.\n",
    "    \"\"\"\n",
    "    City: str = Field(..., description=\"The name of the most populous city\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b471bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "cityParser = PydanticOutputParser(pydantic_object=CityParser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c40c4f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CityParser(City='Atlanta')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = cityParser.parse(\"\"\"{\"City\": \"Atlanta\"}\"\"\")\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7053c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Atlanta'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ca0e3af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['state'], input_types={}, partial_variables={}, template='What is the most populated city in the state provided below.\\n\\nProvide city name and no additional information. \\n\\nExamples:\\n\\nState: Hawaii\\n{{\"City\": \"Honolulu\"}}\\n\\nState: California\\n{{\"City\": \"Los Angeles\"}}\\n\\nState: {state}\\n')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1cdec95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CityParser(City='Atlanta')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm = model.with_structured_output(CityParser)\n",
    "structured_chain = prompt | structured_llm\n",
    "structured_chain.invoke({\"state\": \"Georgia\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765b0d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "774bec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from getpass import getpass\n",
    "\n",
    "# HUGGINGFACEHUB_API_TOKEN = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2dfcc546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "repo_id_flan = \"google/flan-t5-xxl\" \n",
    "\n",
    "\n",
    "llm_google_flan = HuggingFaceHub(\n",
    "    repo_id= repo_id_flan, model_kwargs={\"temperature\": 1, \"max_length\": 64},\n",
    "    huggingfacehub_api_token = HUGGINGFACEHUB_API_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaf5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"state\": \"Georgia\"}\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9db2ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(execute_fewshot_prompt.format(**data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e44dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = execute_fewshot_prompt | llm_google_flan \n",
    "reponse = chain.invoke(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0057d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9562ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "# repo_id_llama_2 = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "repo_id_mistral = \"mistralai/Mistral-7B-Instruct-v0.1\" \n",
    "\n",
    "\n",
    "llm_mistral = HuggingFaceHub(\n",
    "    repo_id= repo_id_mistral, model_kwargs={\"temperature\": 1, \"max_length\": 64},\n",
    "    huggingfacehub_api_token = HUGGINGFACEHUB_API_TOKEN\n",
    ")\n",
    "\n",
    "chain = execute_fewshot_prompt | llm_mistral\n",
    "\n",
    "reponse = chain.invoke(data)\n",
    "\n",
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a26958",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = execute_fewshot_prompt | llm_mistral.bind(stop=\"\\n\")\n",
    "\n",
    "reponse = chain.invoke(data)\n",
    "\n",
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1288cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = execute_fewshot_prompt | llm_mistral.bind(stop=\"\\n\") | cityParser\n",
    "\n",
    "reponse = chain.invoke(data)\n",
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc8f1a-eeb2-4645-b61d-fe0f03283eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import Ollama\n",
    "# from langchain.callbacks.manager import CallbackManager\n",
    "# from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# ollama_llama_llm = Ollama(\n",
    "#     model=\"llama2\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),    \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd76eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d411c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = execute_fewshot_prompt | ollama_llama_llm\n",
    "\n",
    "reponse = chain.invoke(data)\n",
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db999c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f51bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
